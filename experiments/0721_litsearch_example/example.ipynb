{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39881341",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb9022",
   "metadata": {},
   "source": [
    "## Step 1: Load the evaluation data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc1b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0f555",
   "metadata": {},
   "source": [
    "## Step 2: Load the Corpus and Build the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5d891",
   "metadata": {},
   "source": [
    "### Step 2.1: Load the Corpus\n",
    "\n",
    "Note: Deduplicate by chunk format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca7ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafecdf4e59a49ddabc00341405dc755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['corpusid', 'title', 'abstract', 'citations', 'full_paper', 'chunk'],\n",
      "    num_rows: 57657\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "# corpus_s2orc_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_s2orc\", split=\"full\")\n",
    "corpus_clean_data_with_assembled_title_abstract = corpus_clean_data.map(lambda x: {'chunk': f\"Title: {x['title']}\\nAbstract: {x['abstract']}\"})\n",
    "kv = dict()\n",
    "for i in range(len(corpus_clean_data_with_assembled_title_abstract)):\n",
    "    example = corpus_clean_data_with_assembled_title_abstract[i]\n",
    "    kv[example['chunk']] = example\n",
    "corpus_clean_data = corpus_clean_data_with_assembled_title_abstract = Dataset.from_list(list(kv.values()))\n",
    "print(corpus_clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53495f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_clean_data.to_parquet('corpus_clean_dedup.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47716fe5",
   "metadata": {},
   "source": [
    "### Step 2.2: Load the Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6f2e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70596470f76d4021af69113f20470b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GritLM: torch.bfloat16 dtype, mean pool, embedding mode, bbcc attn\n"
     ]
    }
   ],
   "source": [
    "from gritlm import GritLM\n",
    "\n",
    "# Loads the model for both capabilities; If you only need embedding pass `mode=\"embedding\"` to save memory (no lm head)\n",
    "# model = GritLM(\"GritLM/GritLM-7B\", torch_dtype=\"auto\", device_map=\"auto\")\n",
    "model = GritLM(\"GritLM/GritLM-7B\", torch_dtype=\"auto\", device_map=\"auto\", mode='embedding')\n",
    "# To load the 8x7B you will likely need multiple GPUs.\n",
    "# All the kwargs are passed to HF from_pretrained so you can just do the below to load on multiple GPUs:\n",
    "# model = GritLM(\"GritLM/GritLM-8x7B\", torch_dtype=\"auto\", device_map=\"auto\")\n",
    "# You can also load other models e.g.\n",
    "# model = GritLM(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\", pooling_method=\"weighted_mean\", attn=None)\n",
    "# model = GritLM(\"hkunlp/instructor-base\", pooling_method=\"mean\", attn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32543298",
   "metadata": {},
   "source": [
    "### Step 2.3: Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f0d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import torch\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "chroma_client = chromadb.PersistentClient('./chroma')\n",
    "\n",
    "## Embedding/Representation ###\n",
    "instruction = \"Given a research query, retrieve the title and abstract of the relevant research paper\"\n",
    "\n",
    "def gritlm_instruction(instruction):\n",
    "    return \"<|user|>\\n\" + instruction + \"\\n<|embed|>\\n\" if instruction else \"<|embed|>\\n\"\n",
    "\n",
    "def _gritlm_encode_queries(queries: list[str]):\n",
    "    return model.encode(queries, instruction=gritlm_instruction(instruction))\n",
    "\n",
    "def _gritlm_encode_documents(documents: list[str]):\n",
    "    return model.encode(documents, instruction=gritlm_instruction(\"\"))\n",
    "\n",
    "def write_cache(cache_dir, start_idx, end_idx, embeddings):\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    cachefile = os.path.join(cache_dir, f'{start_idx}_to_{end_idx}.pkl')\n",
    "    with open(cachefile, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "\n",
    "def load_cache(cache_dir, start_idx, end_idx):\n",
    "    cachefile = os.path.join(cache_dir, f'{start_idx}_to_{end_idx}.pkl')\n",
    "    if os.path.exists(cachefile):\n",
    "        with open(cachefile, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def gritlm_encode(docs: list[str], encoding_fn, batch_size=256, cache_dir=None):\n",
    "    out = []\n",
    "    for i in tqdm(range(0, len(docs), batch_size),total=math.ceil(len(docs)/batch_size)):\n",
    "        j = min(len(docs), i + batch_size)\n",
    "        batch = docs[i:j]\n",
    "        if cache_dir:\n",
    "            embeddings = load_cache(cache_dir, i, j)\n",
    "            if embeddings is None:\n",
    "                embeddings = encoding_fn(batch)\n",
    "                write_cache(cache_dir, i, j, embeddings)\n",
    "        else:\n",
    "            embeddings = encoding_fn(batch)\n",
    "        out.extend(embeddings)\n",
    "    return out\n",
    "\n",
    "def gritlm_encode_queries(queries: list[str], batch_size=256, cache_dir=None):\n",
    "    return gritlm_encode(queries, _gritlm_encode_queries, batch_size=batch_size, cache_dir=cache_dir)\n",
    "\n",
    "def gritlm_encode_documents(documents: list[str], batch_size=256, cache_dir=None):\n",
    "    return gritlm_encode(documents, _gritlm_encode_documents, batch_size=batch_size, cache_dir=cache_dir)\n",
    "\n",
    "index_name = \"litsearch_corpus\"\n",
    "def gritlm_build_index(documents: list[str], index_name: str, embeddings=None, batch_size=4096):\n",
    "    collection = chroma_client.create_collection(index_name, get_or_create=False)\n",
    "    if embeddings is None:\n",
    "        embeddings = gritlm_encode_documents(documents)\n",
    "    id_list = [str(i) for i in range(len(documents))]\n",
    "    for i in tqdm(range(0, len(documents), batch_size)):\n",
    "        collection.add(ids=id_list[i:i+batch_size], documents=documents[i:i+batch_size], embeddings=embeddings[i:i+batch_size])\n",
    "    return collection\n",
    "\n",
    "def delete_index(index_name:str):\n",
    "    return chroma_client.delete_collection(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54d42d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2e44abafe4249bb3b5317fb8950b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "input(\"going to run indexing again, hit anything to continue... if need new index change cache dir\")\n",
    "documents = corpus_clean_data_with_assembled_title_abstract['chunk'][:]\n",
    "embeddings = gritlm_encode_documents(documents, cache_dir='./embeddings/litsearch')\n",
    "embeddings = np.array(embeddings)\n",
    "# it's already 1 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96362dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57657, 4096) 1.0\n",
      "57657\n"
     ]
    }
   ],
   "source": [
    "# build a faiss index\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "d = embeddings[0].shape[-1]\n",
    "index = faiss.IndexFlatIP(d)   # build the index\n",
    "# embeddings = embeddings / np.linalg.norm(embeddings, axis=-1, keepdims=True) # it's already normalized\n",
    "print(embeddings.shape, np.linalg.norm(embeddings[0]))\n",
    "index.add(embeddings)\n",
    "print(index.ntotal)\n",
    "\n",
    "def faiss_retrieve(query_embeddings, index, k=1):\n",
    "    D, I = index.search(query_embeddings, k)\n",
    "    embeddings_topk = embeddings[I.reshape(-1)].reshape(I.shape + (embeddings.shape[-1],))\n",
    "    return {'distances': D.tolist(), 'ids': I.tolist(), 'embeddings': embeddings_topk.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28e649c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x7fb786b9ff60> >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss.write_index(index, 'faiss/litsearch.index', )\n",
    "faiss.read_index('faiss/litsearch.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a chromadb index\n",
    "build=True\n",
    "if build:\n",
    "    input(\"going to overwrite existing index, hit anything to continue...\")\n",
    "    try:\n",
    "        delete_index(index_name)\n",
    "    except:\n",
    "        pass\n",
    "    index = gritlm_build_index(documents, index_name, embeddings=embeddings)\n",
    "else:\n",
    "    index = chroma_client.get_collection(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab16396",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aac0a000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559861d7fdf487fa0c06097b75168e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc6003ea91147f5b7422a7c4ac92fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "391495884"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings, Collection\n",
    "from datasets import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from faiss import Index\n",
    "result_fields = ('metadatas', 'documents', 'distances', 'embeddings')\n",
    "def gritlm_retrieve(queries, index: Collection | Index, k=5):\n",
    "    query_embeddings = _gritlm_encode_queries(queries)\n",
    "    if isinstance(index, Collection):\n",
    "        results = index.query(query_embeddings=query_embeddings, n_results=k, include=list(result_fields))\n",
    "    elif isinstance(index, Index):\n",
    "        results = faiss_retrieve(query_embeddings, index, k=k)\n",
    "    return results\n",
    "\n",
    "def merge_results(batched_results, result_fields=result_fields):\n",
    "    out = {}\n",
    "    for field in result_fields + ('ids',):\n",
    "        if field in batched_results[0]: # only include existing keys\n",
    "            out[field] = sum([res[field] for res in batched_results], [])\n",
    "    return out\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(len(query_data))):\n",
    "    result = gritlm_retrieve(queries=[query_data[i]['query']], index=index, k=20)\n",
    "    results.append(result)\n",
    "\n",
    "results = merge_results(results)\n",
    "Dataset.from_dict(results).to_parquet('retrieval_results/litsearch.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d64d4",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def map_str_ids_to_corpus_ids(ids, source=corpus_clean_data):\n",
    "    return [source[int(id)]['corpusid'] for id in ids]\n",
    "\n",
    "def recall(predictions, relevant_set):\n",
    "    relevant_count = 0\n",
    "    recall_scores = []\n",
    "    for i, pred in enumerate(predictions):\n",
    "        relevant_count += (pred in relevant_set)\n",
    "        recall_scores.append(relevant_count / len(relevant_set))\n",
    "    return np.array(recall_scores)\n",
    "\n",
    "def print_recall_scores(recall_scores, ks=None):\n",
    "    if ks is None:\n",
    "        ks = list(range(1, len(recall_scores) + 1))\n",
    "    for k in ks:\n",
    "        print(f'recall@{k}: {recall_scores[k-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb9e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5c9c342c744178bddccd16fae519c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "recall@5: 0.6913456169737577\n",
      "recall@20: 0.8001395868230039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cbcae88b0e41be83a42ee71b5cd2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inline specific\n",
      "recall@5: 0.6774891774891775\n",
      "recall@20: 0.7792207792207793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a6510891b1497fa082fd8e13f39f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author specific\n",
      "recall@5: 0.8246445497630331\n",
      "recall@20: 0.8909952606635071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retrieval_results = load_dataset('parquet', data_files='retrieval_results/litsearch.parquet', split='train')\n",
    "assert len(retrieval_results) == len(query_data)\n",
    "\n",
    "# overall\n",
    "recall_scores_all = []\n",
    "for i in tqdm(range(len(retrieval_results))):\n",
    "    if query_data[i]['quality'] == 0: continue\n",
    "    result = retrieval_results[i]\n",
    "    corpus_ids = map_str_ids_to_corpus_ids(result['ids'])\n",
    "    recall_scores = recall(corpus_ids, set(query_data[i]['corpusids']))\n",
    "    recall_scores_all.append(recall_scores)\n",
    "recall_scores_all = np.vstack(recall_scores_all).mean(axis=0)\n",
    "print(\"overall\")\n",
    "print_recall_scores(recall_scores_all, ks=[5,20])\n",
    "\n",
    "recall_scores_all = []\n",
    "for i in tqdm(range(len(retrieval_results))):\n",
    "    if query_data[i]['specificity'] != 1 or \"inline\" not in query_data[i]['query_set']: continue\n",
    "    result = retrieval_results[i]\n",
    "    corpus_ids = map_str_ids_to_corpus_ids(result['ids'])\n",
    "    recall_scores = recall(corpus_ids, set(query_data[i]['corpusids']))\n",
    "    recall_scores_all.append(recall_scores)\n",
    "recall_scores_all = np.vstack(recall_scores_all).mean(axis=0)\n",
    "print(\"inline specific\")\n",
    "print_recall_scores(recall_scores_all, ks=[5,20])\n",
    "\n",
    "recall_scores_all = []\n",
    "for i in tqdm(range(len(retrieval_results))):\n",
    "    if query_data[i]['specificity'] != 1 or \"manual\" not in query_data[i]['query_set']: continue\n",
    "    result = retrieval_results[i]\n",
    "    corpus_ids = map_str_ids_to_corpus_ids(result['ids'])\n",
    "    recall_scores = recall(corpus_ids, set(query_data[i]['corpusids']))\n",
    "    recall_scores_all.append(recall_scores)\n",
    "recall_scores_all = np.vstack(recall_scores_all).mean(axis=0)\n",
    "print(\"author specific\")\n",
    "print_recall_scores(recall_scores_all, ks=[5,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd1531",
   "metadata": {},
   "source": [
    "# Augment the query data with their gritlm recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2b80d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597/597 [00:07<00:00, 75.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "retrieval_results = load_dataset('parquet', data_files='retrieval_results/litsearch.parquet', split='train')\n",
    "recall_scores_all = []\n",
    "for i in tqdm(range(len(retrieval_results))):\n",
    "    if query_data[i]['quality'] == 0: continue\n",
    "    result = retrieval_results[i]\n",
    "    corpus_ids = map_str_ids_to_corpus_ids(result['ids'])\n",
    "    recall_scores = recall(corpus_ids, set(query_data[i]['corpusids']))\n",
    "    recall_scores_all.append(recall_scores)\n",
    "recall_scores_all = np.vstack(recall_scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1493ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7166d4cdfc4f84a3ba3ee1f004b5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c317204845d4a0a8b7a903f98319ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "117734"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data_with_score = query_data.map(lambda ex, i: {'grit_recall': recall_scores_all[i, 19]}, with_indices=True)\n",
    "query_data_with_score.to_parquet('query_with_score.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196acad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
